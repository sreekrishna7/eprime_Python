{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from builtins import range\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "out_dir = r'APA_Scores'\n",
    "All_Scores_out_file = r'APA_Scores_All_Participants.csv'\n",
    "eprime_text_files = glob.glob(\"Raw_Data\\*.txt\")\n",
    "eprime_text_files_len = len(eprime_text_files)\n",
    "\n",
    "def etext_to_df(in_file):\n",
    "    in_dir, infile = os.path.split(in_file)\n",
    "    filename, suffix = os.path.splitext(infile)\n",
    "    if suffix == '.txt':\n",
    "        # Remove first three lines of exported E-Prime tab-delimited text file.\n",
    "        rem_lines = list(range(3))\n",
    "        delimiter_ = '\\t'\n",
    "    elif suffix == '.csv':\n",
    "        # Remove no lines of comma-delimited csv file.\n",
    "        rem_lines = []\n",
    "        delimiter_ = ','\n",
    "    else:\n",
    "        raise Exception('File not txt or csv: {0}'.format(in_file))\n",
    "\n",
    "    df = pd.read_csv(in_file, skiprows=rem_lines, sep=delimiter_)\n",
    "    return df, in_dir, filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcols = ['Subject_ID', 'Age', 'Sex', 'Duration', 'SA_win', 'PA_win', 'SA_RT', 'PA_RT', 'ALL_RT', 'SA_like','PA_like', 'SA_want', 'PA_want', 'IW_SA', 'IW_PA', 'BIAS_SCORE', 'BIAS']\n",
    "out_df = pd.DataFrame(columns=outcols, index=range(eprime_text_files_len))\n",
    "os.mkdir(out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for out_idx, f in enumerate(eprime_text_files):\n",
    "    FullData_df, in_dir, filename = etext_to_df(f)\n",
    "    xml_file = filename+ r'-ExperimentAdvisorReport.xml'\n",
    "    with open(os.path.join(in_dir, xml_file)) as xmlf:\n",
    "        xml_str = ''\n",
    "        for x in range(3):\n",
    "            xml_str = xmlf.readline().strip()\n",
    "    dur_str= re.search('<ElapsedTime.*</ElapsedTime', xml_str).group(0)\n",
    "    Duration = dur_str[28:50]\n",
    "\n",
    "    idx = FullData_df.index[~FullData_df.condition.isna()].tolist() #obtaining valid indexes - without NaN\n",
    "\n",
    "    if 'Descriptor[SubTrial]' in FullData_df.columns:\n",
    "        desc      = 'Descriptor[SubTrial]'\n",
    "    else:\n",
    "        desc      = 'Descriptor'\n",
    "\n",
    "    if 'LeftChoiceDescriptor' in FullData_df.columns:\n",
    "        leftdesc  = 'LeftChoiceDescriptor'\n",
    "    else:\n",
    "        leftdesc  = 'LeftChoiceDescriptor[SubTrial]'\n",
    "\n",
    "    if 'RightChoiceDescriptor' in FullData_df.columns:\n",
    "        rightdesc = 'RightChoiceDescriptor'\n",
    "    else:\n",
    "        rightdesc = 'RightChoiceDescriptor[SubTrial]'\n",
    "\n",
    "    if 'LikeWant[SubTrial]' in FullData_df.columns:\n",
    "        likewant  = 'LikeWant[SubTrial]' \n",
    "    else:    \n",
    "        likewant  = 'LikeWant'\n",
    "\n",
    "    if 'Scale.RT' in FullData_df.columns:\n",
    "        scale_rt  = 'Scale.RT'\n",
    "    else:\n",
    "        scale_rt  = 'Scale.RT[LogLevel5]'\n",
    "\n",
    "    if 'Stimulus.RESP[LogLevel5]' in FullData_df.columns:\n",
    "        stim_resp = 'Stimulus.RESP[LogLevel5]' \n",
    "    else:\n",
    "        stim_resp = 'Stimulus.RESP' \n",
    "\n",
    "    if 'Stimulus.RT[LogLevel5]' in FullData_df.columns:\n",
    "        stim_rt   = 'Stimulus.RT[LogLevel5]'\n",
    "    else:\n",
    "        stim_rt   = 'Stimulus.RT'\n",
    "\n",
    "    Data_df = FullData_df.loc[idx,['condition', 'Subject', 'Age', 'Sex', 'Session', 'SessionDate', 'SessionTime', desc, leftdesc, 'LeftStimulus', rightdesc, 'RightStimulus', likewant, scale_rt, stim_resp, stim_rt]]\n",
    "\n",
    "    out_file = filename+ r'.csv'\n",
    "    Data_df.to_csv(os.path.join(out_dir,out_file))\n",
    "\n",
    "    #Scoring Forced Choice\n",
    "    SP_FCData_df = Data_df[Data_df['condition'] == 'SP'].iloc[:, [14, 15, 9, 11 ]]\n",
    "\n",
    "    def activity_label(row):\n",
    "        if row[0] == 1.0:\n",
    "            activity = row[2]\n",
    "            return activity[0:2]\n",
    "        elif row[0] == 2.0:\n",
    "            activity = row[3]\n",
    "            return activity[0:2]\n",
    "\n",
    "    SP_FCData_df ['Activity'] = SP_FCData_df.apply (lambda row: activity_label(row), axis=1)\n",
    "   \n",
    "    SA_win = len(SP_FCData_df[SP_FCData_df['Activity'] == 'SA'])\n",
    "    PA_win = len(SP_FCData_df[SP_FCData_df['Activity'] == 'PA'])\n",
    "    ALL_RT = SP_FCData_df.iloc[:,[1]].mean()\n",
    "    SA_RT = SP_FCData_df[SP_FCData_df['Activity'] == 'SA'].iloc[:,[1]].mean()\n",
    "    PA_RT = SP_FCData_df[SP_FCData_df['Activity'] == 'PA'].iloc[:,[1]].mean()\n",
    "\n",
    "    #Scoring Liking\n",
    "    LVM_Data_df = Data_df[Data_df.iloc[:,12] == 'Like very much'].iloc[:, [0, 14]]\n",
    "\n",
    "    SA_like = LVM_Data_df[LVM_Data_df['condition'].str.contains('SA', regex=False)].iloc[:,[1]].mean()\n",
    "    PA_like = LVM_Data_df[LVM_Data_df['condition'].str.contains('PA', regex=False)].iloc[:,[1]].mean()\n",
    "\n",
    "    #Scoring Wanting\n",
    "    WVM_Data_df = Data_df[Data_df.iloc[:,12] == 'Want very much'].iloc[:, [0, 14]]\n",
    "\n",
    "    SA_want = WVM_Data_df[WVM_Data_df['condition'].str.contains('SA', regex=False)].iloc[:,[1]].mean()\n",
    "    PA_want = WVM_Data_df[WVM_Data_df['condition'].str.contains('PA', regex=False)].iloc[:,[1]].mean()\n",
    "\n",
    "    # Implicit Wanting (IW) and BIAS_SCORE Calculations\n",
    "    IW_SA = (SA_win * (ALL_RT / SA_RT)) - (PA_win * (ALL_RT / PA_RT))\n",
    "    IW_PA = (PA_win * (ALL_RT / PA_RT)) - (SA_win * (ALL_RT / SA_RT))\n",
    "    BIAS_SCORE = IW_SA - IW_PA\n",
    "\n",
    "    if BIAS_SCORE.item() > 0: #Use .item() for boolean operations on single element series\n",
    "        BIAS = 'SA'\n",
    "    elif BIAS_SCORE.item() < 0:\n",
    "        BIAS = 'PA'\n",
    "    else:\n",
    "        BIAS = 'No Bias'\n",
    "   \n",
    "    outrow = [Data_df.iloc[0]['Subject'], Data_df.iloc[0]['Age'], Data_df.iloc[0]['Sex'], Duration, SA_win, PA_win, SA_RT.item(), PA_RT.item(), ALL_RT.item(), SA_like.item(), PA_like.item(), SA_want.item(), PA_want.item(), IW_SA.item(), IW_PA.item(), BIAS_SCORE.item(), BIAS]\n",
    "\n",
    "    out_df.loc[out_idx] = outrow\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df.to_csv(os.path.join(out_dir,All_Scores_out_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
